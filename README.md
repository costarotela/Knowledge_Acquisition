# Knowledge Acquisition Agent ü§ñ

Sistema avanzado de adquisici√≥n y procesamiento de conocimiento usando m√∫ltiples modelos de lenguaje.

## üó∫Ô∏è Mapa del Proyecto

```
src/
‚îú‚îÄ‚îÄ llm/                    # Gesti√≥n de Modelos de Lenguaje
‚îÇ   ‚îú‚îÄ‚îÄ model_provider.py   # Proveedores de LLM (OpenAI, Groq, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ llm_router.py       # Enrutamiento inteligente de modelos
‚îÇ   ‚îî‚îÄ‚îÄ utils.py           # Utilidades para LLM
‚îú‚îÄ‚îÄ config.py              # Configuraci√≥n centralizada
‚îî‚îÄ‚îÄ ...                    # Otros m√≥dulos
```

## üéØ Funcionalidades Principales

### 1. Sistema Multi-Modelo (LLM)
- **Proveedores Soportados**:
  - OpenAI (GPT-4, GPT-3.5)
  - Groq (Mixtral, LLaMA 2, Gemma)
  - DeepInfra
  - HuggingFace
  - Soporte futuro para modelos locales

- **Enrutamiento Inteligente**:
  - Selecci√≥n autom√°tica del mejor modelo seg√∫n la tarea
  - Optimizaci√≥n de costos y rendimiento
  - Sistema de fallback autom√°tico

- **Tipos de Tareas**:
  - `CODE`: Generaci√≥n y an√°lisis de c√≥digo
  - `CHAT`: Conversaci√≥n general
  - `CLASSIFICATION`: Clasificaci√≥n de texto
  - `SUMMARY`: Generaci√≥n de res√∫menes
  - `EXTRACTION`: Extracci√≥n de informaci√≥n
  - `EMBEDDING`: Generaci√≥n de embeddings

### 2. Configuraci√≥n Flexible
- **Variables de Entorno** (.env):
  ```bash
  # LLM Configuration
  LLM_TYPE=openai|groq|deepinfra|huggingface|local
  LLM_NAME=gpt-4-turbo|mixtral-groq|...
  LLM_TEMPERATURE=0.7
  LLM_STREAMING=False

  # API Keys
  OPENAI_API_KEY=sk-...
  GROQ_API_KEY=gsk-...
  ```

- **Configuraci√≥n de Rutas**:
  ```python
  # En config.py
  LLM_CONFIG = {
      "routes": {
          "CODE": "gpt4",          # Precisi√≥n
          "CHAT": "mixtral",       # Velocidad/Costo
          "CLASSIFICATION": "gpt35" # Suficiente
      }
  }
  ```

## üöÄ Gu√≠a de Uso

### 1. Configuraci√≥n B√°sica
```bash
# 1. Clonar el repositorio
git clone https://github.com/tu-usuario/Knowledge_Acquisition.git

# 2. Crear entorno conda
conda create -n knowledge-acquisition python=3.11
conda activate knowledge-acquisition

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Configurar variables de entorno
cp .env.example .env
# Editar .env con tus API keys
```

### 2. Uso del Sistema Multi-Modelo

```python
from src.llm.utils import get_llm_for_task
from src.llm.llm_router import TaskType

# Obtener el mejor modelo para cada tarea
code_llm = get_llm_for_task(TaskType.CODE)      # Usa GPT-4
chat_llm = get_llm_for_task(TaskType.CHAT)      # Usa Mixtral
summary_llm = get_llm_for_task(TaskType.SUMMARY) # Usa el modelo configurado
```

### 3. Configuraci√≥n Avanzada

```python
from src.llm.llm_router import LLMRouter, TaskType
from src.llm.model_provider import ModelType

# Crear router personalizado
router = LLMRouter()

# Agregar proveedores
router.add_provider(
    name="gpt4",
    model_type=ModelType.OPENAI,
    model_name="gpt-4-turbo"
)

router.add_provider(
    name="mixtral",
    model_type=ModelType.GROQ,
    model_name="mixtral-groq"
)

# Configurar rutas
router.set_route(TaskType.CODE, "gpt4")
router.set_route(TaskType.CHAT, "mixtral")
router.set_fallback("mixtral")
```

## üìã TODO y Pr√≥ximos Pasos

1. **Modelos Locales**
   - [ ] Integraci√≥n con llama.cpp
   - [ ] Soporte para modelos cuantitativos
   - [ ] Gesti√≥n de recursos locales

2. **Optimizaci√≥n**
   - [ ] Sistema de cach√© para respuestas
   - [ ] Balanceo de carga entre modelos
   - [ ] Monitoreo de costos y uso

3. **Nuevas Funcionalidades**
   - [ ] M√°s proveedores de LLM
   - [ ] Nuevos tipos de tareas
   - [ ] Evaluaci√≥n autom√°tica de respuestas

## üìö Documentaci√≥n Adicional

- [Gu√≠a de Desarrollo](docs/development.md)
- [Configuraci√≥n de Modelos](docs/models.md)
- [API Reference](docs/api.md)

## ü§ù Contribuci√≥n

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la licencia MIT. Ver el archivo [LICENSE](LICENSE) para m√°s detalles.
