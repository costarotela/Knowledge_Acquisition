{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Knowledge Acquisition Agent","text":""},{"location":"#overview","title":"Overview","text":"<p>The Knowledge Acquisition Agent is an advanced AI system designed to autonomously acquire, validate, and consolidate knowledge from various sources. It combines web scraping, natural language processing, and machine learning to create a comprehensive and reliable knowledge base.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Multi-source Knowledge Acquisition: Gather information from web pages, YouTube videos, and other sources</li> <li>Intelligent Validation: Verify and cross-reference information for accuracy</li> <li>Knowledge Consolidation: Combine and synthesize information from multiple sources</li> <li>Advanced RAG System: Utilize state-of-the-art retrieval augmented generation</li> <li>Scalable Architecture: Built for growth and extensibility</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Clone the repository\ngit clone https://github.com/costarotela/Knowledge_Acquisition.git\n\n# Install dependencies\npip install -e \".[dev,embeddings]\"\n\n# Set up environment variables\ncp .env.example .env\n# Edit .env with your API keys\n\n# Run example\npython examples/knowledge_consolidation_example.py\n</code></pre>"},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>Knowledge_Acquisition/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 scrapers/       # Web and YouTube scrapers\n\u2502   \u251c\u2500\u2500 embeddings/     # Vector storage and search\n\u2502   \u251c\u2500\u2500 rag/           # Retrieval Augmented Generation\n\u2502   \u2514\u2500\u2500 processors/    # Content processors\n\u251c\u2500\u2500 tests/             # Test suite\n\u251c\u2500\u2500 examples/          # Usage examples\n\u2514\u2500\u2500 docs/             # Documentation\n</code></pre>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome! Please read our Contributing Guidelines for details on how to submit pull requests, report issues, and contribute to the project.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"API/","title":"API Reference","text":""},{"location":"API/#core-apis","title":"Core APIs","text":""},{"location":"API/#youtubeprocessor","title":"YouTubeProcessor","text":"<pre><code>class YouTubeProcessor(AgentProcessor):\n    \"\"\"Procesador de videos de YouTube.\"\"\"\n\n    async def process(self, url: str, context: AgentContext) -&gt; Dict[str, Any]:\n        \"\"\"\n        Procesa un video de YouTube.\n\n        Args:\n            url: URL del video\n            context: Contexto del agente\n\n        Returns:\n            Dict con informaci\u00f3n del video y transcripci\u00f3n\n        \"\"\"\n</code></pre>"},{"location":"API/#agenticnutritionrag","title":"AgenticNutritionRAG","text":"<pre><code>class AgenticNutritionRAG(AgentModel):\n    \"\"\"Modelo RAG para nutrici\u00f3n.\"\"\"\n\n    async def process_video(self, title: str, channel: str, url: str, transcript: str) -&gt; VideoKnowledge:\n        \"\"\"\n        Procesa un video y extrae conocimiento estructurado.\n\n        Args:\n            title: T\u00edtulo del video\n            channel: Canal del video\n            url: URL del video\n            transcript: Transcripci\u00f3n\n\n        Returns:\n            VideoKnowledge con el conocimiento estructurado\n        \"\"\"\n\n    async def get_response(self, query: str, context: List[Dict]) -&gt; RAGResponse:\n        \"\"\"\n        Genera una respuesta usando el modelo.\n\n        Args:\n            query: Consulta del usuario\n            context: Lista de documentos relevantes\n\n        Returns:\n            RAGResponse estructurada\n        \"\"\"\n</code></pre>"},{"location":"API/#data-models","title":"Data Models","text":""},{"location":"API/#videoknowledge","title":"VideoKnowledge","text":"<pre><code>class VideoKnowledge(BaseModel):\n    \"\"\"Conocimiento estructurado extra\u00eddo de un video.\"\"\"\n    title: str\n    channel: str\n    url: str\n    segments: List[VideoSegment]\n    summary: str\n    main_topics: List[str]\n    metadata: Dict[str, Any]\n    processed_at: datetime\n</code></pre>"},{"location":"API/#ragresponse","title":"RAGResponse","text":"<pre><code>class RAGResponse(BaseModel):\n    \"\"\"Respuesta estructurada del sistema RAG.\"\"\"\n    answer: str\n    sources: List[SearchResult]\n    confidence: float\n    reasoning: str\n    follow_up: List[str]\n</code></pre>"},{"location":"API/#database-schema","title":"Database Schema","text":""},{"location":"API/#videos-table","title":"Videos Table","text":"<pre><code>CREATE TABLE videos (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    title TEXT NOT NULL,\n    channel TEXT NOT NULL,\n    url TEXT UNIQUE NOT NULL,\n    transcript TEXT NOT NULL,\n    embedding VECTOR(1536),\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n</code></pre>"},{"location":"API/#video-segments-table","title":"Video Segments Table","text":"<pre><code>CREATE TABLE video_segments (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    video_id UUID REFERENCES videos(id),\n    content TEXT NOT NULL,\n    start_time FLOAT NOT NULL,\n    end_time FLOAT NOT NULL,\n    embedding VECTOR(1536),\n    keywords TEXT[],\n    topics TEXT[],\n    sentiment FLOAT,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n</code></pre>"},{"location":"API/#endpoints","title":"Endpoints","text":""},{"location":"API/#video-processing","title":"Video Processing","text":"<pre><code>POST /api/videos/process\nContent-Type: application/json\n\n{\n    \"url\": \"https://youtube.com/watch?v=...\"\n}\n</code></pre>"},{"location":"API/#query","title":"Query","text":"<pre><code>POST /api/query\nContent-Type: application/json\n\n{\n    \"query\": \"\u00bfQu\u00e9 son los cereales integrales?\",\n    \"context\": {\n        \"language\": \"es\",\n        \"max_results\": 3\n    }\n}\n</code></pre>"},{"location":"API/#error-handling","title":"Error Handling","text":"<p>Todos los endpoints retornan errores en el siguiente formato:</p> <pre><code>{\n    \"error\": {\n        \"code\": \"ERROR_CODE\",\n        \"message\": \"Descripci\u00f3n del error\",\n        \"details\": {\n            \"campo\": \"informaci\u00f3n adicional\"\n        }\n    }\n}\n</code></pre>"},{"location":"API/#codigos-de-error-comunes","title":"C\u00f3digos de Error Comunes","text":"<ul> <li><code>VIDEO_NOT_FOUND</code>: Video no encontrado</li> <li><code>INVALID_URL</code>: URL inv\u00e1lida</li> <li><code>PROCESSING_ERROR</code>: Error procesando video</li> <li><code>TRANSCRIPTION_ERROR</code>: Error obteniendo transcripci\u00f3n</li> <li><code>QUERY_ERROR</code>: Error procesando consulta</li> <li><code>DATABASE_ERROR</code>: Error de base de datos</li> </ul>"},{"location":"API/#rate-limiting","title":"Rate Limiting","text":"<ul> <li>L\u00edmite de 100 requests por hora por IP</li> <li>L\u00edmite de 10 videos procesados por hora por usuario</li> <li>L\u00edmite de 1000 consultas por d\u00eda por usuario</li> </ul>"},{"location":"API/#autenticacion","title":"Autenticaci\u00f3n","text":"<pre><code>POST /api/auth/login\nContent-Type: application/json\n\n{\n    \"email\": \"user@example.com\",\n    \"password\": \"password\"\n}\n</code></pre> <p>Respuesta:</p> <pre><code>{\n    \"access_token\": \"eyJ...\",\n    \"token_type\": \"bearer\",\n    \"expires_in\": 3600\n}\n</code></pre>"},{"location":"API/#websocket-events","title":"WebSocket Events","text":""},{"location":"API/#video-processing-progress","title":"Video Processing Progress","text":"<pre><code>socket.on('video_progress', (data) =&gt; {\n    console.log(data.status, data.progress);\n});\n</code></pre>"},{"location":"API/#query-progress","title":"Query Progress","text":"<p>```javascript socket.on('query_progress', (data) =&gt; {     console.log(data.status, data.context_found); });</p>"},{"location":"CHECKLIST/","title":"Checklist de Verificaci\u00f3n","text":""},{"location":"CHECKLIST/#1-verificacion-de-codigo","title":"1. Verificaci\u00f3n de C\u00f3digo","text":""},{"location":"CHECKLIST/#11-estilo-y-documentacion","title":"1.1 Estilo y Documentaci\u00f3n","text":"<ul> <li>[ ] Docstrings en todas las clases y m\u00e9todos</li> <li>[ ] Tipos anotados (type hints)</li> <li>[ ] Comentarios explicativos en c\u00f3digo complejo</li> <li>[ ] Nombres descriptivos y consistentes</li> <li>[ ] PEP 8 compliance</li> </ul>"},{"location":"CHECKLIST/#12-manejo-de-errores","title":"1.2 Manejo de Errores","text":"<ul> <li>[ ] Try/except en operaciones cr\u00edticas</li> <li>[ ] Mensajes de error descriptivos</li> <li>[ ] Logging apropiado de errores</li> <li>[ ] Recuperaci\u00f3n graceful de fallos</li> <li>[ ] Validaci\u00f3n de entrada</li> </ul>"},{"location":"CHECKLIST/#13-asincronia","title":"1.3 Asincron\u00eda","text":"<ul> <li>[ ] Uso correcto de async/await</li> <li>[ ] Manejo de cancelaci\u00f3n</li> <li>[ ] Timeouts apropiados</li> <li>[ ] Prevenci\u00f3n de race conditions</li> <li>[ ] Gesti\u00f3n de recursos async</li> </ul>"},{"location":"CHECKLIST/#14-estado-y-recursos","title":"1.4 Estado y Recursos","text":"<ul> <li>[ ] Inicializaci\u00f3n correcta</li> <li>[ ] Limpieza de recursos</li> <li>[ ] Estado consistente</li> <li>[ ] Manejo de memoria</li> <li>[ ] Cierre de conexiones</li> </ul>"},{"location":"CHECKLIST/#2-verificacion-de-tests","title":"2. Verificaci\u00f3n de Tests","text":""},{"location":"CHECKLIST/#21-cobertura","title":"2.1 Cobertura","text":"<ul> <li>[ ] Tests unitarios para cada clase</li> <li>[ ] Tests de integraci\u00f3n</li> <li>[ ] Casos de borde</li> <li>[ ] Casos de error</li> <li>[ ] Mocks apropiados</li> </ul>"},{"location":"CHECKLIST/#22-calidad","title":"2.2 Calidad","text":"<ul> <li>[ ] Tests independientes</li> <li>[ ] Setup/teardown correcto</li> <li>[ ] Assertions descriptivas</li> <li>[ ] Fixtures reutilizables</li> <li>[ ] Documentaci\u00f3n de tests</li> </ul>"},{"location":"CHECKLIST/#3-verificacion-de-interfaces","title":"3. Verificaci\u00f3n de Interfaces","text":""},{"location":"CHECKLIST/#31-web-streamlit","title":"3.1 Web (Streamlit)","text":"<ul> <li>[ ] Responsive design</li> <li>[ ] Manejo de estado de sesi\u00f3n</li> <li>[ ] Feedback al usuario</li> <li>[ ] Validaci\u00f3n de entrada</li> <li>[ ] Manejo de errores UI</li> </ul>"},{"location":"CHECKLIST/#32-voz","title":"3.2 Voz","text":"<ul> <li>[ ] Calidad de audio</li> <li>[ ] Feedback de grabaci\u00f3n</li> <li>[ ] Timeouts apropiados</li> <li>[ ] Manejo de ruido</li> <li>[ ] Estado de micr\u00f3fono</li> </ul>"},{"location":"CHECKLIST/#4-verificacion-de-modelos","title":"4. Verificaci\u00f3n de Modelos","text":""},{"location":"CHECKLIST/#41-rag","title":"4.1 RAG","text":"<ul> <li>[ ] Calidad de embeddings</li> <li>[ ] Relevancia de resultados</li> <li>[ ] Tiempo de respuesta</li> <li>[ ] Uso de memoria</li> <li>[ ] Cach\u00e9 efectivo</li> </ul>"},{"location":"CHECKLIST/#42-whisper","title":"4.2 Whisper","text":"<ul> <li>[ ] Precisi\u00f3n de transcripci\u00f3n</li> <li>[ ] Manejo de acentos</li> <li>[ ] Rendimiento en tiempo real</li> <li>[ ] Uso de recursos</li> <li>[ ] Fallback options</li> </ul>"},{"location":"CHECKLIST/#5-verificacion-de-seguridad","title":"5. Verificaci\u00f3n de Seguridad","text":""},{"location":"CHECKLIST/#51-datos","title":"5.1 Datos","text":"<ul> <li>[ ] Sanitizaci\u00f3n de entrada</li> <li>[ ] Protecci\u00f3n de API keys</li> <li>[ ] Manejo seguro de archivos</li> <li>[ ] Validaci\u00f3n de datos</li> <li>[ ] L\u00edmites de tama\u00f1o</li> </ul>"},{"location":"CHECKLIST/#52-acceso","title":"5.2 Acceso","text":"<ul> <li>[ ] Control de acceso</li> <li>[ ] Rate limiting</li> <li>[ ] Validaci\u00f3n de sesi\u00f3n</li> <li>[ ] Logging de accesos</li> <li>[ ] Timeouts de sesi\u00f3n</li> </ul>"},{"location":"CHECKLIST/#6-verificacion-de-rendimiento","title":"6. Verificaci\u00f3n de Rendimiento","text":""},{"location":"CHECKLIST/#61-recursos","title":"6.1 Recursos","text":"<ul> <li>[ ] Uso de CPU</li> <li>[ ] Uso de memoria</li> <li>[ ] Uso de disco</li> <li>[ ] Uso de red</li> <li>[ ] Escalabilidad</li> </ul>"},{"location":"CHECKLIST/#62-tiempos","title":"6.2 Tiempos","text":"<ul> <li>[ ] Latencia de respuesta</li> <li>[ ] Tiempo de procesamiento</li> <li>[ ] Tiempo de carga</li> <li>[ ] Tiempo de inicializaci\u00f3n</li> <li>[ ] Timeouts</li> </ul>"},{"location":"CHECKLIST/#7-verificacion-de-documentacion","title":"7. Verificaci\u00f3n de Documentaci\u00f3n","text":""},{"location":"CHECKLIST/#71-tecnica","title":"7.1 T\u00e9cnica","text":"<ul> <li>[ ] Diagramas actualizados</li> <li>[ ] API documentada</li> <li>[ ] Ejemplos de uso</li> <li>[ ] Gu\u00eda de troubleshooting</li> <li>[ ] Notas de implementaci\u00f3n</li> </ul>"},{"location":"CHECKLIST/#72-usuario","title":"7.2 Usuario","text":"<ul> <li>[ ] Manual de usuario</li> <li>[ ] Gu\u00eda de instalaci\u00f3n</li> <li>[ ] FAQ</li> <li>[ ] Ejemplos pr\u00e1cticos</li> <li>[ ] Contacto de soporte</li> </ul>"},{"location":"CHECKLIST/#8-verificacion-de-configuracion","title":"8. Verificaci\u00f3n de Configuraci\u00f3n","text":""},{"location":"CHECKLIST/#81-ambiente","title":"8.1 Ambiente","text":"<ul> <li>[ ] Variables de entorno</li> <li>[ ] Archivos de configuraci\u00f3n</li> <li>[ ] Dependencias</li> <li>[ ] Versiones compatibles</li> <li>[ ] Scripts de setup</li> </ul>"},{"location":"CHECKLIST/#82-deployment","title":"8.2 Deployment","text":"<ul> <li>[ ] Scripts de deployment</li> <li>[ ] Backup strategy</li> <li>[ ] Rollback plan</li> <li>[ ] Monitoreo</li> <li>[ ] Alertas</li> </ul>"},{"location":"CONTRIBUTING/","title":"Gu\u00eda de Contribuci\u00f3n","text":""},{"location":"CONTRIBUTING/#introduccion","title":"Introducci\u00f3n","text":"<p>\u00a1Gracias por tu inter\u00e9s en contribuir al Sistema de Adquisici\u00f3n de Conocimiento Nutricional! Este documento proporciona las pautas y mejores pr\u00e1cticas para contribuir al proyecto.</p>"},{"location":"CONTRIBUTING/#codigo-de-conducta","title":"C\u00f3digo de Conducta","text":"<p>Este proyecto se adhiere al Contributor Covenant. Al participar, se espera que mantengas este c\u00f3digo.</p>"},{"location":"CONTRIBUTING/#como-contribuir","title":"C\u00f3mo Contribuir","text":""},{"location":"CONTRIBUTING/#1-configuracion-del-entorno","title":"1. Configuraci\u00f3n del Entorno","text":"<ol> <li>Fork el repositorio</li> <li> <p>Clonar tu fork: <pre><code>git clone https://github.com/TU_USERNAME/Knowledge_Acquisition.git\n</code></pre></p> </li> <li> <p>Configurar el repositorio upstream: <pre><code>git remote add upstream https://github.com/ORIGINAL_OWNER/Knowledge_Acquisition.git\n</code></pre></p> </li> <li> <p>Crear entorno Conda: <pre><code>conda create -n knowledge_acquisition python=3.8\nconda activate knowledge_acquisition\n\n# Instalar dependencias\nconda install --file requirements.txt\nconda install --file requirements-dev.txt\n\n# Para paquetes que no est\u00e9n en conda\npip install -r requirements-pip.txt\npip install -r requirements-dev-pip.txt\n</code></pre></p> </li> </ol>"},{"location":"CONTRIBUTING/#2-desarrollo","title":"2. Desarrollo","text":""},{"location":"CONTRIBUTING/#estructura-de-ramas","title":"Estructura de Ramas","text":"<ul> <li><code>main</code>: Rama principal, producci\u00f3n</li> <li><code>develop</code>: Rama de desarrollo</li> <li><code>feature/*</code>: Nuevas caracter\u00edsticas</li> <li><code>bugfix/*</code>: Correcciones de bugs</li> <li><code>docs/*</code>: Actualizaciones de documentaci\u00f3n</li> </ul>"},{"location":"CONTRIBUTING/#flujo-de-trabajo","title":"Flujo de Trabajo","text":"<ol> <li> <p>Crear rama desde <code>develop</code>: <pre><code>git checkout develop\ngit pull upstream develop\ngit checkout -b feature/nueva-caracteristica\n</code></pre></p> </li> <li> <p>Desarrollar con buenas pr\u00e1cticas:</p> </li> <li>Seguir gu\u00eda de estilo PEP 8</li> <li>A\u00f1adir tests unitarios</li> <li>Documentar c\u00f3digo nuevo</li> <li> <p>Mantener commits at\u00f3micos</p> </li> <li> <p>Ejecutar tests: <pre><code>pytest tests/\n</code></pre></p> </li> <li> <p>Verificar estilo: <pre><code>flake8 src/\nblack src/ --check\n</code></pre></p> </li> </ol>"},{"location":"CONTRIBUTING/#3-pull-requests","title":"3. Pull Requests","text":"<ol> <li> <p>Actualizar tu rama: <pre><code>git fetch upstream\ngit rebase upstream/develop\n</code></pre></p> </li> <li> <p>Crear Pull Request:</p> </li> <li>T\u00edtulo descriptivo</li> <li>Descripci\u00f3n detallada</li> <li>Referencias a issues</li> <li> <p>Screenshots si aplica</p> </li> <li> <p>Esperar review</p> </li> <li>Atender feedback</li> <li>Merge (por mantenedores)</li> </ol>"},{"location":"CONTRIBUTING/#estandares-de-codigo","title":"Est\u00e1ndares de C\u00f3digo","text":""},{"location":"CONTRIBUTING/#python","title":"Python","text":"<ul> <li>Python 3.8+</li> <li>PEP 8</li> <li>Tipos est\u00e1ticos</li> <li>Docstrings Google style</li> </ul> <pre><code>def funcion_ejemplo(param1: str, param2: int) -&gt; Dict[str, Any]:\n    \"\"\"Descripci\u00f3n breve.\n\n    Args:\n        param1: Descripci\u00f3n del par\u00e1metro\n        param2: Descripci\u00f3n del par\u00e1metro\n\n    Returns:\n        Dict con resultados\n\n    Raises:\n        ValueError: Descripci\u00f3n del error\n    \"\"\"\n</code></pre>"},{"location":"CONTRIBUTING/#tests","title":"Tests","text":"<ul> <li>pytest</li> <li>Coverage &gt; 80%</li> <li>Fixtures reutilizables</li> <li>Mocking apropiado</li> </ul> <pre><code>def test_funcion_ejemplo(mock_dependencia):\n    # Arrange\n    entrada = \"test\"\n\n    # Act\n    resultado = funcion_ejemplo(entrada)\n\n    # Assert\n    assert resultado[\"campo\"] == \"valor\"\n</code></pre>"},{"location":"CONTRIBUTING/#documentacion","title":"Documentaci\u00f3n","text":"<ul> <li>Markdown</li> <li>Diagramas con Mermaid</li> <li>Ejemplos de c\u00f3digo</li> <li>Referencias API</li> </ul>"},{"location":"CONTRIBUTING/#reportar-issues","title":"Reportar Issues","text":""},{"location":"CONTRIBUTING/#bugs","title":"Bugs","text":"<pre><code>### Descripci\u00f3n\nDescripci\u00f3n clara y concisa\n\n### Pasos para Reproducir\n1. Paso 1\n2. Paso 2\n3. ...\n\n### Comportamiento Esperado\nQu\u00e9 deber\u00eda suceder\n\n### Comportamiento Actual\nQu\u00e9 est\u00e1 sucediendo\n\n### Contexto Adicional\n- OS: Linux\n- Python: 3.8.5\n- Dependencias relevantes\n</code></pre>"},{"location":"CONTRIBUTING/#features","title":"Features","text":"<pre><code>### Descripci\u00f3n\nQu\u00e9 necesidad resuelve\n\n### Casos de Uso\n- Caso 1\n- Caso 2\n\n### Implementaci\u00f3n Sugerida\nIdeas iniciales\n\n### Alternativas Consideradas\nOtras opciones y por qu\u00e9 no\n</code></pre>"},{"location":"CONTRIBUTING/#versionado","title":"Versionado","text":"<p>Seguimos Semantic Versioning:</p> <ul> <li>MAJOR: Cambios incompatibles</li> <li>MINOR: Funcionalidad nueva compatible</li> <li>PATCH: Correcciones compatibles</li> </ul>"},{"location":"CONTRIBUTING/#changelog","title":"Changelog","text":"<p>Mantener CHANGELOG.md actualizado:</p> <pre><code>## [1.1.0] - 2024-02-11\n\n### A\u00f1adido\n- Nueva caracter\u00edstica X\n- Soporte para Y\n\n### Cambiado\n- Mejora en Z\n- Actualizaci\u00f3n de W\n\n### Corregido\n- Bug en A\n- Error en B\n</code></pre>"},{"location":"CONTRIBUTING/#licencia","title":"Licencia","text":"<p>Al contribuir, aceptas que tu c\u00f3digo se distribuya bajo la misma licencia del proyecto (MIT).</p>"},{"location":"DESIGN/","title":"Dise\u00f1o del Sistema de Adquisici\u00f3n de Conocimiento Nutricional","text":""},{"location":"DESIGN/#1-vision-general","title":"1. Visi\u00f3n General","text":"<p>Sistema avanzado de adquisici\u00f3n y consulta de conocimiento nutricional que utiliza procesamiento de lenguaje natural y t\u00e9cnicas de RAG (Retrieval-Augmented Generation) para proporcionar respuestas precisas sobre nutrici\u00f3n deportiva.</p>"},{"location":"DESIGN/#2-arquitectura-del-sistema","title":"2. Arquitectura del Sistema","text":""},{"location":"DESIGN/#21-componentes-principales","title":"2.1 Componentes Principales","text":"<pre><code>Knowledge_Acquisition/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 agent/\n\u2502   \u2502   \u251c\u2500\u2500 core/         # Componentes base y utilidades\n\u2502   \u2502   \u251c\u2500\u2500 interfaces/   # Interfaces de usuario\n\u2502   \u2502   \u2514\u2500\u2500 models/       # Modelos de IA y procesadores\n\u2502   \u251c\u2500\u2500 auth/            # Autenticaci\u00f3n y seguridad\n\u2502   \u2514\u2500\u2500 youtube_processor.py  # Procesamiento de videos\n\u251c\u2500\u2500 app.py              # Aplicaci\u00f3n principal\n\u2514\u2500\u2500 docs/              # Documentaci\u00f3n\n</code></pre>"},{"location":"DESIGN/#22-flujo-de-datos","title":"2.2 Flujo de Datos","text":"<pre><code>graph TD\n    A[Usuario] --&gt;|Consulta| B[Interfaz Web]\n    B --&gt;|URL YouTube| C[YouTubeProcessor]\n    C --&gt;|Transcripci\u00f3n| D[AgenticNutritionRAG]\n    D --&gt;|Embeddings| E[Supabase]\n    F[Usuario] --&gt;|Pregunta| G[QueryProcessor]\n    G --&gt;|Consulta Estructurada| D\n    D --&gt;|B\u00fasqueda| E\n    E --&gt;|Contexto| D\n    D --&gt;|Respuesta| B\n</code></pre>"},{"location":"DESIGN/#3-componentes-detallados","title":"3. Componentes Detallados","text":""},{"location":"DESIGN/#31-procesador-de-youtube","title":"3.1 Procesador de YouTube","text":"<ul> <li>Extracci\u00f3n de transcripciones multiling\u00fces</li> <li>Procesamiento as\u00edncrono de metadata</li> <li>Manejo robusto de errores</li> <li>Integraci\u00f3n con API de YouTube</li> </ul>"},{"location":"DESIGN/#32-sistema-rag-agenticnutritionrag","title":"3.2 Sistema RAG (AgenticNutritionRAG)","text":"<ul> <li>Modelo base: GPT-3.5-turbo</li> <li>Embeddings sem\u00e1nticos</li> <li>Procesamiento en dos fases:</li> <li>B\u00fasqueda vectorial inicial</li> <li>Refinamiento por relevancia</li> </ul>"},{"location":"DESIGN/#321-procesamiento-de-consultas","title":"3.2.1 Procesamiento de Consultas","text":"<ul> <li>Extracci\u00f3n de palabras clave</li> <li>Eliminaci\u00f3n de stop words</li> <li>An\u00e1lisis de intenci\u00f3n</li> <li>Estructuraci\u00f3n de consultas</li> </ul>"},{"location":"DESIGN/#322-busqueda-de-contexto","title":"3.2.2 B\u00fasqueda de Contexto","text":"<ul> <li>Fragmentaci\u00f3n inteligente de texto</li> <li>Sistema de puntuaci\u00f3n multifactorial:</li> <li>Coincidencia de palabras clave</li> <li>Similitud sem\u00e1ntica</li> <li>Longitud \u00f3ptima</li> <li>Coherencia contextual</li> </ul>"},{"location":"DESIGN/#33-base-de-conocimiento-supabase","title":"3.3 Base de Conocimiento (Supabase)","text":"<ul> <li>Almacenamiento vectorial</li> <li>B\u00fasqueda por similitud</li> <li>Indexaci\u00f3n eficiente</li> <li>Cach\u00e9 de resultados</li> </ul>"},{"location":"DESIGN/#4-procesamiento-inteligente","title":"4. Procesamiento Inteligente","text":""},{"location":"DESIGN/#41-extraccion-de-conocimiento","title":"4.1 Extracci\u00f3n de Conocimiento","text":"<ul> <li>Segmentaci\u00f3n de video</li> <li>Identificaci\u00f3n de temas clave</li> <li>Extracci\u00f3n de conceptos</li> <li>Relaciones sem\u00e1nticas</li> </ul>"},{"location":"DESIGN/#42-generacion-de-respuestas","title":"4.2 Generaci\u00f3n de Respuestas","text":"<ul> <li>Contextualizaci\u00f3n inteligente</li> <li>Verificaci\u00f3n de fuentes</li> <li>Adaptaci\u00f3n al usuario</li> <li>Explicaciones estructuradas</li> </ul>"},{"location":"DESIGN/#5-mejoras-implementadas","title":"5. Mejoras Implementadas","text":""},{"location":"DESIGN/#51-procesamiento-de-videos","title":"5.1 Procesamiento de Videos","text":"<ul> <li>[x] Extracci\u00f3n robusta de transcripciones</li> <li>[x] Manejo de m\u00faltiples idiomas</li> <li>[x] Procesamiento paralelo</li> <li>[x] Gesti\u00f3n de errores</li> </ul>"},{"location":"DESIGN/#52-sistema-rag","title":"5.2 Sistema RAG","text":"<ul> <li>[x] Fragmentaci\u00f3n inteligente</li> <li>[x] Puntuaci\u00f3n avanzada</li> <li>[x] B\u00fasqueda en dos fases</li> <li>[x] Contextualizaci\u00f3n mejorada</li> </ul>"},{"location":"DESIGN/#53-interfaz-de-usuario","title":"5.3 Interfaz de Usuario","text":"<ul> <li>[x] Dise\u00f1o responsive</li> <li>[x] Feedback en tiempo real</li> <li>[x] Manejo de errores amigable</li> <li>[x] Historial de consultas</li> </ul>"},{"location":"DESIGN/#6-proximas-mejoras","title":"6. Pr\u00f3ximas Mejoras","text":""},{"location":"DESIGN/#61-corto-plazo","title":"6.1 Corto Plazo","text":"<ul> <li>[ ] Implementar cach\u00e9 de embeddings</li> <li>[ ] Mejorar extracci\u00f3n de palabras clave</li> <li>[ ] A\u00f1adir an\u00e1lisis de sentimiento</li> <li>[ ] Optimizar b\u00fasqueda vectorial</li> </ul>"},{"location":"DESIGN/#62-largo-plazo","title":"6.2 Largo Plazo","text":"<ul> <li>[ ] Implementar aprendizaje continuo</li> <li>[ ] A\u00f1adir verificaci\u00f3n de fuentes</li> <li>[ ] Expandir base de conocimiento</li> <li>[ ] Mejorar personalizaci\u00f3n</li> </ul>"},{"location":"DESIGN/#7-consideraciones-tecnicas","title":"7. Consideraciones T\u00e9cnicas","text":""},{"location":"DESIGN/#71-rendimiento","title":"7.1 Rendimiento","text":"<ul> <li>Optimizaci\u00f3n de consultas</li> <li>Cach\u00e9 estrat\u00e9gico</li> <li>Procesamiento as\u00edncrono</li> <li>Gesti\u00f3n de recursos</li> </ul>"},{"location":"DESIGN/#72-seguridad","title":"7.2 Seguridad","text":"<ul> <li>Validaci\u00f3n de entrada</li> <li>Sanitizaci\u00f3n de salida</li> <li>Gesti\u00f3n segura de API keys</li> <li>Control de acceso</li> </ul>"},{"location":"DESIGN/#73-escalabilidad","title":"7.3 Escalabilidad","text":"<ul> <li>Dise\u00f1o modular</li> <li>Componentes desacoplados</li> <li>Interfaces extensibles</li> <li>Configuraci\u00f3n flexible</li> </ul>"},{"location":"DESIGN/#8-documentacion-adicional","title":"8. Documentaci\u00f3n Adicional","text":"<ul> <li>README.md: Gu\u00eda de inicio r\u00e1pido</li> <li>API.md: Documentaci\u00f3n de la API</li> <li>CONTRIBUTING.md: Gu\u00eda de contribuci\u00f3n</li> </ul>"},{"location":"api/embeddings/","title":"Embeddings API Reference","text":""},{"location":"api/embeddings/#overview","title":"Overview","text":"<p>The Embeddings API provides functionality for generating, storing, and managing vector embeddings of text content.</p>"},{"location":"api/embeddings/#core-components","title":"Core Components","text":""},{"location":"api/embeddings/#embeddinggenerator","title":"EmbeddingGenerator","text":"<pre><code>class EmbeddingGenerator:\n    def __init__(self, model: str = \"text-embedding-3-large\"):\n        \"\"\"\n        Initialize embedding generator.\n\n        Args:\n            model (str): Name of the embedding model to use\n        \"\"\"\n        pass\n\n    async def generate(self, text: str) -&gt; np.ndarray:\n        \"\"\"\n        Generate embedding for a single text.\n\n        Args:\n            text (str): Input text\n\n        Returns:\n            np.ndarray: Vector embedding\n        \"\"\"\n        pass\n\n    async def generate_batch(self, texts: List[str]) -&gt; np.ndarray:\n        \"\"\"\n        Generate embeddings for multiple texts.\n\n        Args:\n            texts (List[str]): List of input texts\n\n        Returns:\n            np.ndarray: Matrix of embeddings\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/embeddings/#textchunker","title":"TextChunker","text":"<pre><code>class TextChunker:\n    def __init__(self, chunk_size: int = 1000, overlap: int = 200):\n        \"\"\"\n        Initialize text chunker.\n\n        Args:\n            chunk_size (int): Maximum chunk size in characters\n            overlap (int): Overlap between chunks\n        \"\"\"\n        pass\n\n    def chunk_text(self, text: str) -&gt; List[str]:\n        \"\"\"\n        Split text into overlapping chunks.\n\n        Args:\n            text (str): Input text\n\n        Returns:\n            List[str]: List of text chunks\n        \"\"\"\n        pass\n\n    def chunk_document(self, document: Document) -&gt; List[TextChunk]:\n        \"\"\"\n        Split document into chunks with metadata.\n\n        Args:\n            document (Document): Input document\n\n        Returns:\n            List[TextChunk]: List of chunks with metadata\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/embeddings/#storage-components","title":"Storage Components","text":""},{"location":"api/embeddings/#vectorstore","title":"VectorStore","text":"<pre><code>class VectorStore:\n    def __init__(self, dimension: int, index_type: str = \"HNSW\"):\n        \"\"\"\n        Initialize vector store.\n\n        Args:\n            dimension (int): Embedding dimension\n            index_type (str): Type of index to use\n        \"\"\"\n        pass\n\n    async def add(self, id: str, vector: np.ndarray, metadata: Dict = None):\n        \"\"\"\n        Add vector to store.\n\n        Args:\n            id (str): Unique identifier\n            vector (np.ndarray): Vector embedding\n            metadata (Dict): Optional metadata\n        \"\"\"\n        pass\n\n    async def search(self, query: np.ndarray, k: int = 10) -&gt; List[SearchResult]:\n        \"\"\"\n        Search for similar vectors.\n\n        Args:\n            query (np.ndarray): Query vector\n            k (int): Number of results\n\n        Returns:\n            List[SearchResult]: Similar vectors with scores\n        \"\"\"\n        pass\n\n    def save(self, path: str):\n        \"\"\"\n        Save index to disk.\n\n        Args:\n            path (str): Save path\n        \"\"\"\n        pass\n\n    @classmethod\n    def load(cls, path: str) -&gt; \"VectorStore\":\n        \"\"\"\n        Load index from disk.\n\n        Args:\n            path (str): Load path\n\n        Returns:\n            VectorStore: Loaded vector store\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/embeddings/#utility-classes","title":"Utility Classes","text":""},{"location":"api/embeddings/#searchresult","title":"SearchResult","text":"<pre><code>@dataclass\nclass SearchResult:\n    id: str\n    vector: np.ndarray\n    score: float\n    metadata: Dict[str, Any]\n</code></pre>"},{"location":"api/embeddings/#textchunk","title":"TextChunk","text":"<pre><code>@dataclass\nclass TextChunk:\n    text: str\n    start_char: int\n    end_char: int\n    metadata: Dict[str, Any]\n</code></pre>"},{"location":"api/embeddings/#configuration","title":"Configuration","text":""},{"location":"api/embeddings/#embeddingconfig","title":"EmbeddingConfig","text":"<pre><code>@dataclass\nclass EmbeddingConfig:\n    model: str = \"text-embedding-3-large\"\n    dimension: int = 1536\n    batch_size: int = 32\n    cache_dir: str = \"./cache\"\n</code></pre>"},{"location":"api/embeddings/#vectorstoreconfig","title":"VectorStoreConfig","text":"<pre><code>@dataclass\nclass VectorStoreConfig:\n    dimension: int = 1536\n    index_type: str = \"HNSW\"\n    space: str = \"cosine\"\n    ef_construction: int = 200\n    M: int = 16\n</code></pre>"},{"location":"api/embeddings/#usage-examples","title":"Usage Examples","text":"<pre><code># Generate embeddings\ngenerator = EmbeddingGenerator()\nembedding = await generator.generate(\"Example text\")\n\n# Chunk text\nchunker = TextChunker(chunk_size=1000, overlap=200)\nchunks = chunker.chunk_text(long_text)\n\n# Store vectors\nstore = VectorStore(dimension=1536)\nawait store.add(\"doc1\", embedding)\n\n# Search vectors\nresults = await store.search(query_vector, k=10)\n\n# Process document\ndoc_chunks = chunker.chunk_document(document)\nembeddings = await generator.generate_batch([chunk.text for chunk in doc_chunks])\nfor chunk, emb in zip(doc_chunks, embeddings):\n    await store.add(chunk.id, emb, chunk.metadata)\n</code></pre>"},{"location":"api/rag/","title":"RAG (Retrieval-Augmented Generation) API Reference","text":""},{"location":"api/rag/#overview","title":"Overview","text":"<p>The RAG API provides components for implementing Retrieval-Augmented Generation systems, combining vector search with language models for enhanced knowledge retrieval and generation.</p>"},{"location":"api/rag/#core-components","title":"Core Components","text":""},{"location":"api/rag/#ragsystem","title":"RAGSystem","text":"<pre><code>class RAGSystem:\n    def __init__(self, config: RAGConfig):\n        \"\"\"\n        Initialize RAG system.\n\n        Args:\n            config (RAGConfig): System configuration\n        \"\"\"\n        pass\n\n    async def query(self, question: str) -&gt; RAGResponse:\n        \"\"\"\n        Process a query through the RAG pipeline.\n\n        Args:\n            question (str): User question\n\n        Returns:\n            RAGResponse: Generated response with sources\n        \"\"\"\n        pass\n\n    async def add_knowledge(self, content: str, metadata: Dict[str, Any] = None):\n        \"\"\"\n        Add new knowledge to the system.\n\n        Args:\n            content (str): Content to add\n            metadata (Dict): Optional metadata\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/rag/#retriever","title":"Retriever","text":"<pre><code>class Retriever:\n    def __init__(self, vector_store: VectorStore):\n        \"\"\"\n        Initialize retriever.\n\n        Args:\n            vector_store (VectorStore): Vector store for similarity search\n        \"\"\"\n        pass\n\n    async def retrieve(self, query: str, k: int = 5) -&gt; List[Document]:\n        \"\"\"\n        Retrieve relevant documents for a query.\n\n        Args:\n            query (str): Query string\n            k (int): Number of documents to retrieve\n\n        Returns:\n            List[Document]: Retrieved documents\n        \"\"\"\n        pass\n\n    def rerank(self, query: str, documents: List[Document]) -&gt; List[Document]:\n        \"\"\"\n        Rerank retrieved documents by relevance.\n\n        Args:\n            query (str): Original query\n            documents (List[Document]): Retrieved documents\n\n        Returns:\n            List[Document]: Reranked documents\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/rag/#generator","title":"Generator","text":"<pre><code>class Generator:\n    def __init__(self, model: str = \"gpt-4-turbo-preview\"):\n        \"\"\"\n        Initialize generator.\n\n        Args:\n            model (str): Language model to use\n        \"\"\"\n        pass\n\n    async def generate(self, \n                      query: str, \n                      context: List[str]) -&gt; GeneratedResponse:\n        \"\"\"\n        Generate response using retrieved context.\n\n        Args:\n            query (str): User query\n            context (List[str]): Retrieved context\n\n        Returns:\n            GeneratedResponse: Generated response\n        \"\"\"\n        pass\n\n    def validate_response(self, \n                         response: str, \n                         context: List[str]) -&gt; bool:\n        \"\"\"\n        Validate generated response against context.\n\n        Args:\n            response (str): Generated response\n            context (List[str]): Source context\n\n        Returns:\n            bool: True if response is valid\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/rag/#data-classes","title":"Data Classes","text":""},{"location":"api/rag/#ragconfig","title":"RAGConfig","text":"<pre><code>@dataclass\nclass RAGConfig:\n    retriever_k: int = 5\n    max_tokens: int = 2000\n    temperature: float = 0.7\n    model: str = \"gpt-4-turbo-preview\"\n    rerank_threshold: float = 0.7\n</code></pre>"},{"location":"api/rag/#ragresponse","title":"RAGResponse","text":"<pre><code>@dataclass\nclass RAGResponse:\n    answer: str\n    sources: List[Source]\n    confidence: float\n    metadata: Dict[str, Any]\n</code></pre>"},{"location":"api/rag/#source","title":"Source","text":"<pre><code>@dataclass\nclass Source:\n    content: str\n    relevance_score: float\n    metadata: Dict[str, Any]\n</code></pre>"},{"location":"api/rag/#generatedresponse","title":"GeneratedResponse","text":"<pre><code>@dataclass\nclass GeneratedResponse:\n    text: str\n    tokens_used: int\n    finish_reason: str\n    metadata: Dict[str, Any]\n</code></pre>"},{"location":"api/rag/#utility-functions","title":"Utility Functions","text":"<pre><code>def prepare_context(documents: List[Document], \n                   max_tokens: int) -&gt; str:\n    \"\"\"\n    Prepare retrieved documents as context.\n\n    Args:\n        documents (List[Document]): Retrieved documents\n        max_tokens (int): Maximum context length\n\n    Returns:\n        str: Prepared context\n    \"\"\"\n    pass\n\ndef evaluate_response(response: str, \n                     ground_truth: str) -&gt; Dict[str, float]:\n    \"\"\"\n    Evaluate response quality.\n\n    Args:\n        response (str): Generated response\n        ground_truth (str): Ground truth answer\n\n    Returns:\n        Dict[str, float]: Evaluation metrics\n    \"\"\"\n    pass\n\ndef extract_citations(response: str, \n                     sources: List[Source]) -&gt; List[Citation]:\n    \"\"\"\n    Extract source citations from response.\n\n    Args:\n        response (str): Generated response\n        sources (List[Source]): Source documents\n\n    Returns:\n        List[Citation]: Extracted citations\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/rag/#usage-examples","title":"Usage Examples","text":"<pre><code># Initialize RAG system\nconfig = RAGConfig(retriever_k=5, temperature=0.7)\nrag = RAGSystem(config)\n\n# Add knowledge\nawait rag.add_knowledge(\n    content=\"Important information...\",\n    metadata={\"source\": \"document1.pdf\"}\n)\n\n# Query the system\nresponse = await rag.query(\"What is the capital of France?\")\nprint(f\"Answer: {response.answer}\")\nprint(f\"Sources: {response.sources}\")\n\n# Direct retriever usage\nretriever = Retriever(vector_store)\ndocs = await retriever.retrieve(\"query\", k=5)\nreranked_docs = retriever.rerank(\"query\", docs)\n\n# Direct generator usage\ngenerator = Generator()\nresponse = await generator.generate(\n    query=\"What is ML?\",\n    context=[\"Machine learning is...\"]\n)\n</code></pre>"},{"location":"api/rag/#error-handling","title":"Error Handling","text":"<pre><code>class RAGError(Exception):\n    \"\"\"Base class for RAG exceptions.\"\"\"\n    pass\n\nclass RetrievalError(RAGError):\n    \"\"\"Raised when document retrieval fails.\"\"\"\n    pass\n\nclass GenerationError(RAGError):\n    \"\"\"Raised when response generation fails.\"\"\"\n    pass\n\nclass ValidationError(RAGError):\n    \"\"\"Raised when response validation fails.\"\"\"\n    pass\n</code></pre>"},{"location":"api/scrapers/","title":"Scrapers API Reference","text":""},{"location":"api/scrapers/#overview","title":"Overview","text":"<p>The Scrapers API provides interfaces for extracting content from various sources including web pages, PDFs, and structured data sources.</p>"},{"location":"api/scrapers/#web-scraper","title":"Web Scraper","text":""},{"location":"api/scrapers/#webscraper-class","title":"WebScraper Class","text":"<pre><code>class WebScraper:\n    def __init__(self, config: ScraperConfig = None):\n        \"\"\"\n        Initialize web scraper with optional configuration.\n\n        Args:\n            config (ScraperConfig): Configuration for the scraper\n        \"\"\"\n        pass\n\n    async def scrape_url(self, url: str) -&gt; ScrapedContent:\n        \"\"\"\n        Scrape content from a single URL.\n\n        Args:\n            url (str): URL to scrape\n\n        Returns:\n            ScrapedContent: Extracted content and metadata\n        \"\"\"\n        pass\n\n    async def scrape_urls(self, urls: List[str]) -&gt; List[ScrapedContent]:\n        \"\"\"\n        Scrape content from multiple URLs in parallel.\n\n        Args:\n            urls (List[str]): List of URLs to scrape\n\n        Returns:\n            List[ScrapedContent]: List of extracted contents\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/scrapers/#scraperconfig-class","title":"ScraperConfig Class","text":"<pre><code>@dataclass\nclass ScraperConfig:\n    max_depth: int = 3\n    respect_robots_txt: bool = True\n    request_delay: float = 1.0\n    timeout: int = 30\n    headers: Dict[str, str] = field(default_factory=dict)\n    cookies: Dict[str, str] = field(default_factory=dict)\n</code></pre>"},{"location":"api/scrapers/#scrapedcontent-class","title":"ScrapedContent Class","text":"<pre><code>@dataclass\nclass ScrapedContent:\n    url: str\n    title: str\n    text: str\n    html: str\n    metadata: Dict[str, Any]\n    timestamp: datetime\n    status: ScrapingStatus\n</code></pre>"},{"location":"api/scrapers/#pdf-scraper","title":"PDF Scraper","text":""},{"location":"api/scrapers/#pdfscraper-class","title":"PDFScraper Class","text":"<pre><code>class PDFScraper:\n    def __init__(self, config: PDFConfig = None):\n        \"\"\"\n        Initialize PDF scraper with optional configuration.\n\n        Args:\n            config (PDFConfig): Configuration for PDF processing\n        \"\"\"\n        pass\n\n    def extract_text(self, file_path: str) -&gt; PDFContent:\n        \"\"\"\n        Extract text content from a PDF file.\n\n        Args:\n            file_path (str): Path to PDF file\n\n        Returns:\n            PDFContent: Extracted content and metadata\n        \"\"\"\n        pass\n\n    def extract_tables(self, file_path: str) -&gt; List[Table]:\n        \"\"\"\n        Extract tables from a PDF file.\n\n        Args:\n            file_path (str): Path to PDF file\n\n        Returns:\n            List[Table]: List of extracted tables\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/scrapers/#data-source-scraper","title":"Data Source Scraper","text":""},{"location":"api/scrapers/#datasourcescraper-class","title":"DataSourceScraper Class","text":"<pre><code>class DataSourceScraper:\n    def __init__(self, connection_string: str):\n        \"\"\"\n        Initialize data source scraper.\n\n        Args:\n            connection_string (str): Database connection string\n        \"\"\"\n        pass\n\n    async def extract_data(self, query: str) -&gt; DataFrame:\n        \"\"\"\n        Extract data using SQL query.\n\n        Args:\n            query (str): SQL query to execute\n\n        Returns:\n            DataFrame: Extracted data\n        \"\"\"\n        pass\n\n    async def extract_schema(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Extract database schema information.\n\n        Returns:\n            Dict[str, Any]: Database schema\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/scrapers/#utility-functions","title":"Utility Functions","text":"<pre><code>def validate_url(url: str) -&gt; bool:\n    \"\"\"\n    Validate URL format and accessibility.\n\n    Args:\n        url (str): URL to validate\n\n    Returns:\n        bool: True if valid and accessible\n    \"\"\"\n    pass\n\ndef clean_text(text: str) -&gt; str:\n    \"\"\"\n    Clean and normalize extracted text.\n\n    Args:\n        text (str): Text to clean\n\n    Returns:\n        str: Cleaned text\n    \"\"\"\n    pass\n\ndef extract_metadata(content: Any) -&gt; Dict[str, Any]:\n    \"\"\"\n    Extract metadata from content.\n\n    Args:\n        content (Any): Content to analyze\n\n    Returns:\n        Dict[str, Any]: Extracted metadata\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/scrapers/#error-handling","title":"Error Handling","text":"<pre><code>class ScraperError(Exception):\n    \"\"\"Base class for scraper exceptions.\"\"\"\n    pass\n\nclass URLError(ScraperError):\n    \"\"\"Raised when URL is invalid or inaccessible.\"\"\"\n    pass\n\nclass PDFError(ScraperError):\n    \"\"\"Raised when PDF processing fails.\"\"\"\n    pass\n\nclass DataSourceError(ScraperError):\n    \"\"\"Raised when data source access fails.\"\"\"\n    pass\n</code></pre>"},{"location":"api/scrapers/#usage-examples","title":"Usage Examples","text":"<pre><code># Web scraping example\nscraper = WebScraper(ScraperConfig(max_depth=2))\ncontent = await scraper.scrape_url(\"https://example.com\")\n\n# PDF processing example\npdf_scraper = PDFScraper()\npdf_content = pdf_scraper.extract_text(\"document.pdf\")\n\n# Data source example\ndb_scraper = DataSourceScraper(\"postgresql://localhost/db\")\ndata = await db_scraper.extract_data(\"SELECT * FROM table\")\n</code></pre>"},{"location":"architecture/components/","title":"Components","text":""},{"location":"architecture/components/#core-components","title":"Core Components","text":""},{"location":"architecture/components/#knowledge-acquisition-agent","title":"Knowledge Acquisition Agent","text":"<p>The main component responsible for orchestrating the knowledge acquisition process. It coordinates between different modules and manages the flow of information.</p>"},{"location":"architecture/components/#data-scrapers","title":"Data Scrapers","text":"<p>Collection of specialized scrapers for different data sources: - Web scrapers - PDF processors - Video content analyzers - Social media integrators</p>"},{"location":"architecture/components/#knowledge-processor","title":"Knowledge Processor","text":"<p>Responsible for: - Text extraction and cleaning - Entity recognition - Relationship mapping - Knowledge graph construction</p>"},{"location":"architecture/components/#rag-system","title":"RAG System","text":"<p>The Retrieval-Augmented Generation system includes: - Vector database for efficient similarity search - Embedding generator - Context retriever - Response generator</p>"},{"location":"architecture/components/#supporting-components","title":"Supporting Components","text":""},{"location":"architecture/components/#storage-system","title":"Storage System","text":"<ul> <li>Document store</li> <li>Vector database</li> <li>Knowledge graph database</li> <li>Cache system</li> </ul>"},{"location":"architecture/components/#api-layer","title":"API Layer","text":"<p>RESTful API providing: - Data ingestion endpoints - Query endpoints - Management endpoints</p>"},{"location":"architecture/components/#monitoring-logging","title":"Monitoring &amp; Logging","text":"<ul> <li>Performance metrics</li> <li>Error tracking</li> <li>Usage statistics</li> <li>Audit logs</li> </ul>"},{"location":"architecture/components/#integration-components","title":"Integration Components","text":""},{"location":"architecture/components/#external-apis","title":"External APIs","text":"<ul> <li>OpenAI API integration</li> <li>Other LLM providers</li> <li>Authentication services</li> <li>Cloud storage services</li> </ul>"},{"location":"architecture/components/#user-interface","title":"User Interface","text":"<ul> <li>Web interface</li> <li>API documentation</li> <li>Management dashboard</li> <li>Visualization tools</li> </ul>"},{"location":"architecture/data-flow/","title":"Data Flow","text":""},{"location":"architecture/data-flow/#input-processing-flow","title":"Input Processing Flow","text":"<ol> <li>Data Ingestion</li> <li>Raw data input from various sources</li> <li>Initial validation and format checking</li> <li> <p>Queue management for processing</p> </li> <li> <p>Content Extraction</p> </li> <li>Text extraction from different formats</li> <li>Media processing (images, videos)</li> <li> <p>Metadata extraction</p> </li> <li> <p>Data Preprocessing</p> </li> <li>Text cleaning and normalization</li> <li>Language detection</li> <li>Format standardization</li> </ol>"},{"location":"architecture/data-flow/#knowledge-processing-flow","title":"Knowledge Processing Flow","text":"<ol> <li>Analysis Phase</li> <li>Entity extraction</li> <li>Relationship identification</li> <li>Topic modeling</li> <li> <p>Sentiment analysis</p> </li> <li> <p>Knowledge Graph Construction</p> </li> <li>Entity mapping</li> <li>Relationship mapping</li> <li>Graph validation</li> <li> <p>Consistency checking</p> </li> <li> <p>Embedding Generation</p> </li> <li>Text chunking</li> <li>Embedding computation</li> <li>Vector storage</li> <li>Index updates</li> </ol>"},{"location":"architecture/data-flow/#query-processing-flow","title":"Query Processing Flow","text":"<ol> <li>Query Analysis</li> <li>Query parsing</li> <li>Intent recognition</li> <li> <p>Context extraction</p> </li> <li> <p>Knowledge Retrieval</p> </li> <li>Vector similarity search</li> <li>Graph traversal</li> <li> <p>Context assembly</p> </li> <li> <p>Response Generation</p> </li> <li>Context-aware generation</li> <li>Response validation</li> <li>Format adaptation</li> </ol>"},{"location":"architecture/data-flow/#data-storage-flow","title":"Data Storage Flow","text":"<ol> <li>Temporary Storage</li> <li>Processing cache</li> <li>Session data</li> <li> <p>Intermediate results</p> </li> <li> <p>Permanent Storage</p> </li> <li>Document store</li> <li>Vector database</li> <li>Knowledge graph</li> <li> <p>Audit logs</p> </li> <li> <p>Backup and Recovery</p> </li> <li>Regular backups</li> <li>Version control</li> <li>Recovery procedures</li> </ol>"},{"location":"architecture/data-flow/#system-integration-flow","title":"System Integration Flow","text":"<ol> <li>API Integration</li> <li>Request handling</li> <li>Authentication</li> <li>Rate limiting</li> <li> <p>Response formatting</p> </li> <li> <p>External Services</p> </li> <li>LLM API calls</li> <li>Cloud storage sync</li> <li> <p>Third-party integrations</p> </li> <li> <p>Monitoring Flow</p> </li> <li>Performance metrics</li> <li>Error tracking</li> <li>Usage statistics</li> <li>System health checks</li> </ol>"},{"location":"architecture/overview/","title":"Architecture Overview","text":"<p>The Knowledge Acquisition Agent is built with a modular, scalable architecture that enables efficient knowledge gathering, processing, and consolidation.</p>"},{"location":"architecture/overview/#core-components","title":"Core Components","text":""},{"location":"architecture/overview/#1-scraping-module","title":"1. Scraping Module","text":"<ul> <li>Advanced web crawler</li> <li>YouTube data extraction</li> <li>Rate limiting and error handling</li> </ul>"},{"location":"architecture/overview/#2-embeddings-module","title":"2. Embeddings Module","text":"<ul> <li>Vector storage with FAISS</li> <li>Semantic search capabilities</li> <li>Efficient data indexing</li> </ul>"},{"location":"architecture/overview/#3-rag-system","title":"3. RAG System","text":"<ul> <li>Knowledge retrieval</li> <li>Context-aware generation</li> <li>Information synthesis</li> </ul>"},{"location":"architecture/overview/#4-knowledge-graph","title":"4. Knowledge Graph","text":"<ul> <li>Relationship tracking</li> <li>Validation history</li> <li>Confidence scoring</li> </ul>"},{"location":"database/","title":"Esquema de Base de Datos para Procesamiento de Video","text":"<p>Este documento describe la estructura de la base de datos utilizada para el almacenamiento y recuperaci\u00f3n de conocimiento basado en video.</p>"},{"location":"database/#estructura-general","title":"Estructura General","text":"<p>El esquema est\u00e1 dise\u00f1ado para soportar: - Almacenamiento eficiente de videos y sus metadatos - B\u00fasqueda por similitud (texto y visual) - Recuperaci\u00f3n temporal precisa - Trazabilidad del conocimiento</p>"},{"location":"database/#tablas-principales","title":"Tablas Principales","text":""},{"location":"database/#1-video_knowledge_items","title":"1. video_knowledge_items","text":"<p>Almacena informaci\u00f3n principal sobre cada video procesado.</p> <pre><code>CREATE TABLE video_knowledge_items (\n    id UUID PRIMARY KEY,\n    knowledge_item_id BIGINT,      -- Referencia a knowledge_items general\n    summary TEXT,                  -- Resumen del contenido\n    main_topics TEXT[],           -- Temas principales\n    metadata JSONB,               -- Metadatos flexibles\n    quality_metrics JSONB,        -- M\u00e9tricas de calidad\n    processed_at TIMESTAMPTZ,     -- Fecha de procesamiento\n    updated_at TIMESTAMPTZ,       -- \u00daltima actualizaci\u00f3n\n    video_metadata JSONB,         -- Metadatos espec\u00edficos de video\n    created_at TIMESTAMPTZ        -- Fecha de creaci\u00f3n\n);\n</code></pre>"},{"location":"database/#2-knowledge_fragments","title":"2. knowledge_fragments","text":"<p>Almacena fragmentos de video con an\u00e1lisis sem\u00e1ntico y visual.</p> <pre><code>CREATE TABLE knowledge_fragments (\n    id UUID PRIMARY KEY,\n    video_item_id UUID,           -- Referencia al video\n    content TEXT,                 -- Contenido textual\n    start_time FLOAT,            -- Inicio del fragmento\n    end_time FLOAT,              -- Fin del fragmento\n    keywords TEXT[],             -- Palabras clave\n    topics TEXT[],               -- Temas detectados\n    confidence_score FLOAT,      -- Confianza del an\u00e1lisis\n    embedding vector(384),       -- Embedding textual\n    frame_count INTEGER,         -- N\u00famero de frames\n    scene_change BOOLEAN,        -- Indicador de cambio de escena\n    visual_features JSONB,       -- Caracter\u00edsticas visuales\n    frame_embeddings vector(512)[], -- Embeddings de frames\n    dominant_colors TEXT[],      -- Colores dominantes\n    motion_intensity FLOAT,      -- Intensidad de movimiento\n    created_at TIMESTAMPTZ       -- Fecha de creaci\u00f3n\n);\n</code></pre>"},{"location":"database/#3-video_frames","title":"3. video_frames","text":"<p>Almacena frames clave con an\u00e1lisis visual.</p> <pre><code>CREATE TABLE video_frames (\n    id UUID PRIMARY KEY,\n    fragment_id UUID,            -- Referencia al fragmento\n    timestamp FLOAT,             -- Tiempo en el video\n    frame_path TEXT,             -- Ruta al archivo\n    embedding vector(512),       -- Embedding visual\n    objects_detected JSONB,      -- Objetos detectados\n    scene_score FLOAT,           -- Relevancia de la escena\n    visual_features JSONB,       -- Caracter\u00edsticas visuales\n    created_at TIMESTAMPTZ       -- Fecha de creaci\u00f3n\n);\n</code></pre>"},{"location":"database/#4-video_citations","title":"4. video_citations","text":"<p>Gestiona referencias a momentos espec\u00edficos en videos.</p> <pre><code>CREATE TABLE video_citations (\n    id UUID PRIMARY KEY,\n    video_item_id UUID,          -- Referencia al video\n    text TEXT,                   -- Texto de la cita\n    source_url TEXT,             -- URL fuente\n    context TEXT,                -- Contexto\n    timestamp FLOAT,             -- Tiempo en el video\n    frame_reference UUID,        -- Referencia al frame\n    accessed_date TIMESTAMPTZ,   -- Fecha de acceso\n    created_at TIMESTAMPTZ       -- Fecha de creaci\u00f3n\n);\n</code></pre>"},{"location":"database/#indices","title":"\u00cdndices","text":""},{"location":"database/#indices-vectoriales","title":"\u00cdndices Vectoriales","text":"<pre><code>-- Para b\u00fasqueda por similitud textual\nCREATE INDEX idx_fragments_embedding \nON knowledge_fragments USING ivfflat (embedding vector_cosine_ops);\n\n-- Para b\u00fasqueda por similitud visual\nCREATE INDEX idx_frames_embedding \nON video_frames USING ivfflat (embedding vector_cosine_ops);\n</code></pre>"},{"location":"database/#indices-temporales","title":"\u00cdndices Temporales","text":"<pre><code>-- Para b\u00fasqueda por rango temporal\nCREATE INDEX idx_fragments_time_range \nON knowledge_fragments(start_time, end_time) \nWHERE start_time IS NOT NULL AND end_time IS NOT NULL;\n\n-- Para b\u00fasqueda por timestamp\nCREATE INDEX idx_frames_timestamp \nON video_frames(timestamp);\n</code></pre>"},{"location":"database/#indices-de-relaciones","title":"\u00cdndices de Relaciones","text":"<pre><code>CREATE INDEX idx_fragments_video_item_id ON knowledge_fragments(video_item_id);\nCREATE INDEX idx_video_citations_item_id ON video_citations(video_item_id);\n</code></pre>"},{"location":"database/#funcion-de-busqueda","title":"Funci\u00f3n de B\u00fasqueda","text":"<p>La funci\u00f3n <code>match_video_fragments</code> permite b\u00fasqueda multimodal:</p> <pre><code>match_video_fragments(\n    query_embedding vector(384),          -- Embedding de texto\n    visual_query_embedding vector(512),   -- Embedding visual\n    match_threshold float DEFAULT 0.7,    -- Umbral de similitud\n    match_count int DEFAULT 10           -- N\u00famero de resultados\n)\n</code></pre>"},{"location":"database/#caracteristicas","title":"Caracter\u00edsticas","text":"<ul> <li>B\u00fasqueda combinada de texto y visual</li> <li>Ponderaci\u00f3n configurable (40% visual, 60% texto)</li> <li>Filtrado por umbral de similitud</li> <li>L\u00edmite de resultados configurable</li> </ul>"},{"location":"database/#uso-con-el-agente-inteligente","title":"Uso con el Agente Inteligente","text":"<p>Este esquema permite al agente: 1. Almacenar y recuperar conocimiento de videos de forma eficiente 2. Realizar b\u00fasquedas sem\u00e1nticas en contenido textual y visual 3. Referenciar momentos espec\u00edficos en videos 4. Mantener contexto y trazabilidad del conocimiento 5. Evaluar la calidad y relevancia del contenido</p>"},{"location":"database/#mantenimiento","title":"Mantenimiento","text":"<p>Para mantener el rendimiento \u00f3ptimo: 1. Monitorear el crecimiento de las tablas 2. Reindexar peri\u00f3dicamente los \u00edndices vectoriales 3. Vaciar regularmente los frames antiguos no referenciados 4. Mantener actualizadas las estad\u00edsticas de la base de datos</p>"},{"location":"database/SCHEMA/","title":"Diagrama del Esquema de Base de Datos","text":"<pre><code>erDiagram\n    knowledge_items ||--o{ video_knowledge_items : \"extends\"\n    video_knowledge_items ||--o{ knowledge_fragments : \"contains\"\n    knowledge_fragments ||--o{ video_frames : \"has\"\n    video_knowledge_items ||--o{ video_citations : \"references\"\n    video_frames ||--o{ video_citations : \"referenced_by\"\n\n    knowledge_items {\n        bigint id PK\n        text source_url\n        text concept\n        text content\n        float evidence_score\n        float novelty_score\n        jsonb reference_list\n        vector embedding\n        text category\n        timestamptz created_at\n    }\n\n    video_knowledge_items {\n        uuid id PK\n        bigint knowledge_item_id FK\n        text summary\n        text[] main_topics\n        jsonb metadata\n        jsonb quality_metrics\n        timestamptz processed_at\n        timestamptz updated_at\n        jsonb video_metadata\n        timestamptz created_at\n    }\n\n    knowledge_fragments {\n        uuid id PK\n        uuid video_item_id FK\n        text content\n        float start_time\n        float end_time\n        text[] keywords\n        text[] topics\n        float confidence_score\n        vector(384) embedding\n        integer frame_count\n        boolean scene_change\n        jsonb visual_features\n        vector(512)[] frame_embeddings\n        text[] dominant_colors\n        float motion_intensity\n        timestamptz created_at\n    }\n\n    video_frames {\n        uuid id PK\n        uuid fragment_id FK\n        float timestamp\n        text frame_path\n        vector(512) embedding\n        jsonb objects_detected\n        float scene_score\n        jsonb visual_features\n        timestamptz created_at\n    }\n\n    video_citations {\n        uuid id PK\n        uuid video_item_id FK\n        text text\n        text source_url\n        text context\n        float timestamp\n        uuid frame_reference FK\n        timestamptz accessed_date\n        timestamptz created_at\n    }\n</code></pre>"},{"location":"database/SCHEMA/#notas-sobre-el-diagrama","title":"Notas sobre el Diagrama","text":""},{"location":"database/SCHEMA/#relaciones","title":"Relaciones","text":"<ul> <li><code>knowledge_items</code> \u2192 <code>video_knowledge_items</code>: Extensi\u00f3n para videos</li> <li><code>video_knowledge_items</code> \u2192 <code>knowledge_fragments</code>: Segmentaci\u00f3n temporal</li> <li><code>knowledge_fragments</code> \u2192 <code>video_frames</code>: Frames clave</li> <li><code>video_knowledge_items</code> \u2192 <code>video_citations</code>: Referencias</li> <li><code>video_frames</code> \u2192 <code>video_citations</code>: Referencias precisas</li> </ul>"},{"location":"database/SCHEMA/#tipos-especiales","title":"Tipos Especiales","text":"<ul> <li><code>vector(384)</code>: Embeddings de texto</li> <li><code>vector(512)</code>: Embeddings visuales</li> <li><code>jsonb</code>: Datos estructurados flexibles</li> <li><code>text[]</code>: Arrays de texto para etiquetas</li> </ul>"},{"location":"database/SCHEMA/#indices-importantes","title":"\u00cdndices Importantes","text":"<ul> <li>Vectoriales: <code>embedding</code> en fragments y frames</li> <li>Temporales: <code>(start_time, end_time)</code> y <code>timestamp</code></li> <li>Relacionales: Referencias entre tablas</li> </ul>"},{"location":"guide/configuration/","title":"Configuration Guide","text":""},{"location":"guide/configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"guide/configuration/#required-variables","title":"Required Variables","text":"<pre><code># OpenAI Configuration\nOPENAI_API_KEY=your-api-key\nOPENAI_MODEL=gpt-4-turbo-preview\n\n# Database Configuration\nDATABASE_URL=postgresql://user:password@localhost:5432/knowledge_db\nVECTOR_STORE_PATH=./vector_store\n\n# Application Settings\nAPP_ENV=development\nLOG_LEVEL=INFO\n</code></pre>"},{"location":"guide/configuration/#optional-variables","title":"Optional Variables","text":"<pre><code># Performance Tuning\nBATCH_SIZE=100\nMAX_WORKERS=4\nCACHE_TTL=3600\n\n# Feature Flags\nENABLE_MONITORING=true\nENABLE_RATE_LIMITING=true\n</code></pre>"},{"location":"guide/configuration/#database-configuration","title":"Database Configuration","text":""},{"location":"guide/configuration/#postgresql-setup","title":"PostgreSQL Setup","text":"<ol> <li> <p>Create database: <pre><code>CREATE DATABASE knowledge_db;\n</code></pre></p> </li> <li> <p>Initialize tables: <pre><code>python scripts/init_db.py\n</code></pre></p> </li> <li> <p>Configure connection: <pre><code>DATABASE_URL=postgresql://user:password@localhost:5432/knowledge_db\n</code></pre></p> </li> </ol>"},{"location":"guide/configuration/#vector-store-configuration","title":"Vector Store Configuration","text":""},{"location":"guide/configuration/#local-vector-store","title":"Local Vector Store","text":"<pre><code>VECTOR_STORE_PATH=./vector_store\nVECTOR_DIMENSION=1536\nINDEX_TYPE=HNSW\n</code></pre>"},{"location":"guide/configuration/#cloud-vector-store","title":"Cloud Vector Store","text":"<pre><code>VECTOR_STORE_TYPE=pinecone\nPINECONE_API_KEY=your-key\nPINECONE_ENV=production\n</code></pre>"},{"location":"guide/configuration/#scraping-configuration","title":"Scraping Configuration","text":""},{"location":"guide/configuration/#web-scraping","title":"Web Scraping","text":"<pre><code>MAX_DEPTH=3\nRESPECT_ROBOTS_TXT=true\nREQUEST_DELAY=1.0\n</code></pre>"},{"location":"guide/configuration/#rate-limiting","title":"Rate Limiting","text":"<pre><code>RATE_LIMIT_REQUESTS=100\nRATE_LIMIT_PERIOD=60\n</code></pre>"},{"location":"guide/configuration/#monitoring-configuration","title":"Monitoring Configuration","text":""},{"location":"guide/configuration/#logging","title":"Logging","text":"<pre><code>LOG_LEVEL=INFO\nLOG_FORMAT=json\nLOG_FILE=./logs/app.log\n</code></pre>"},{"location":"guide/configuration/#metrics","title":"Metrics","text":"<pre><code>ENABLE_METRICS=true\nMETRICS_PORT=9090\n</code></pre>"},{"location":"guide/configuration/#security-configuration","title":"Security Configuration","text":""},{"location":"guide/configuration/#api-security","title":"API Security","text":"<pre><code>API_KEY_REQUIRED=true\nJWT_SECRET=your-secret\nTOKEN_EXPIRY=3600\n</code></pre>"},{"location":"guide/configuration/#cors-settings","title":"CORS Settings","text":"<pre><code>ALLOWED_ORIGINS=[\"http://localhost:3000\"]\nALLOWED_METHODS=[\"GET\", \"POST\"]\n</code></pre>"},{"location":"guide/configuration/#cache-configuration","title":"Cache Configuration","text":""},{"location":"guide/configuration/#redis-cache","title":"Redis Cache","text":"<pre><code>REDIS_URL=redis://localhost:6379\nCACHE_TTL=3600\n</code></pre>"},{"location":"guide/configuration/#local-cache","title":"Local Cache","text":"<pre><code>CACHE_TYPE=local\nCACHE_SIZE=1000\n</code></pre>"},{"location":"guide/configuration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"guide/configuration/#llm-settings","title":"LLM Settings","text":"<pre><code>MODEL_TEMPERATURE=0.7\nMAX_TOKENS=2000\nTOP_P=0.95\n</code></pre>"},{"location":"guide/configuration/#embedding-settings","title":"Embedding Settings","text":"<pre><code>EMBEDDING_MODEL=text-embedding-3-large\nCHUNK_SIZE=1000\nCHUNK_OVERLAP=200\n</code></pre>"},{"location":"guide/examples/","title":"Examples","text":""},{"location":"guide/examples/#basic-usage-examples","title":"Basic Usage Examples","text":""},{"location":"guide/examples/#1-adding-a-web-source","title":"1. Adding a Web Source","text":"<pre><code>from knowledge_acquisition import KnowledgeAgent\n\nagent = KnowledgeAgent()\n\n# Add a single URL\nurl = \"https://example.com/article\"\nresult = agent.add_source(url)\nprint(f\"Added source: {result.source_id}\")\n\n# Add multiple URLs\nurls = [\n    \"https://example.com/article1\",\n    \"https://example.com/article2\"\n]\nresults = agent.add_sources(urls)\n</code></pre>"},{"location":"guide/examples/#2-processing-documents","title":"2. Processing Documents","text":"<pre><code># Process a PDF document\nwith open(\"document.pdf\", \"rb\") as f:\n    result = agent.process_document(f, \"pdf\")\n\n# Process a text file\nwith open(\"data.txt\", \"r\") as f:\n    result = agent.process_document(f, \"text\")\n</code></pre>"},{"location":"guide/examples/#3-querying-knowledge","title":"3. Querying Knowledge","text":"<pre><code># Simple query\nresponse = agent.query(\"What are the main topics in the processed documents?\")\n\n# Advanced query with filters\nresponse = agent.query(\n    \"What are the key findings?\",\n    filters={\n        \"date_range\": [\"2024-01-01\", \"2024-02-01\"],\n        \"confidence\": 0.8\n    }\n)\n</code></pre>"},{"location":"guide/examples/#advanced-examples","title":"Advanced Examples","text":""},{"location":"guide/examples/#1-custom-knowledge-processing","title":"1. Custom Knowledge Processing","text":"<pre><code>from knowledge_acquisition import Processor, KnowledgeGraph\n\nclass CustomProcessor(Processor):\n    def process(self, content):\n        # Custom processing logic\n        entities = self.extract_entities(content)\n        relationships = self.find_relationships(entities)\n        return KnowledgeGraph(entities, relationships)\n\n# Use custom processor\nagent = KnowledgeAgent(processor=CustomProcessor())\n</code></pre>"},{"location":"guide/examples/#2-batch-processing","title":"2. Batch Processing","text":"<pre><code># Process multiple sources in batch\nsources = [\n    {\"type\": \"url\", \"content\": \"https://example.com/1\"},\n    {\"type\": \"file\", \"content\": \"document1.pdf\"},\n    {\"type\": \"text\", \"content\": \"Some text content\"}\n]\n\nresults = agent.process_batch(\n    sources,\n    batch_size=10,\n    max_workers=4\n)\n</code></pre>"},{"location":"guide/examples/#3-knowledge-graph-navigation","title":"3. Knowledge Graph Navigation","text":"<pre><code># Get related concepts\nrelated = agent.find_related(\"artificial intelligence\")\n\n# Find paths between concepts\npath = agent.find_path(\n    start=\"machine learning\",\n    end=\"neural networks\"\n)\n\n# Get concept clusters\nclusters = agent.cluster_concepts(\n    concept=\"data science\",\n    max_distance=2\n)\n</code></pre>"},{"location":"guide/examples/#4-export-and-integration","title":"4. Export and Integration","text":"<pre><code># Export to different formats\nagent.export_knowledge(\"output.json\", format=\"json\")\nagent.export_knowledge(\"graph.gml\", format=\"gml\")\n\n# Integration with other tools\nneo4j_export = agent.to_neo4j(\n    uri=\"bolt://localhost:7687\",\n    user=\"neo4j\",\n    password=\"password\"\n)\n</code></pre>"},{"location":"guide/examples/#5-monitoring-and-analytics","title":"5. Monitoring and Analytics","text":"<pre><code># Get processing statistics\nstats = agent.get_stats()\n\n# Monitor specific source\nsource_status = agent.monitor_source(\"source_id\")\n\n# Get knowledge graph metrics\nmetrics = agent.graph_metrics()\n</code></pre>"},{"location":"guide/examples/#api-integration-examples","title":"API Integration Examples","text":""},{"location":"guide/examples/#1-rest-api-usage","title":"1. REST API Usage","text":"<pre><code>import requests\n\n# Configuration\nAPI_URL = \"http://localhost:8000/api/v1\"\nAPI_KEY = \"your-api-key\"\n\n# Add source\nresponse = requests.post(\n    f\"{API_URL}/sources\",\n    headers={\"Authorization\": f\"Bearer {API_KEY}\"},\n    json={\"url\": \"https://example.com/article\"}\n)\n\n# Query knowledge\nresponse = requests.post(\n    f\"{API_URL}/query\",\n    headers={\"Authorization\": f\"Bearer {API_KEY}\"},\n    json={\"query\": \"What are the main topics?\"}\n)\n</code></pre>"},{"location":"guide/examples/#2-webhook-integration","title":"2. Webhook Integration","text":"<pre><code>from flask import Flask, request\n\napp = Flask(__name__)\n\n@app.route(\"/webhook\", methods=[\"POST\"])\ndef handle_webhook():\n    data = request.json\n\n    # Process webhook data\n    if data[\"event\"] == \"processing_complete\":\n        source_id = data[\"source_id\"]\n        status = data[\"status\"]\n        # Handle the event\n\n    return {\"status\": \"success\"}\n</code></pre>"},{"location":"guide/getting-started/","title":"Getting Started","text":""},{"location":"guide/getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>Conda (Miniconda or Anaconda)</li> <li>Git</li> <li>OpenAI API key</li> <li>PostgreSQL (for vector storage)</li> </ul>"},{"location":"guide/getting-started/#installation","title":"Installation","text":"<ol> <li> <p>Clone the repository: <pre><code>git clone https://github.com/costarotela/Knowledge_Acquisition.git\ncd Knowledge_Acquisition\n</code></pre></p> </li> <li> <p>Create and activate the conda environment: <pre><code>conda env create -f environment.yml\nconda activate knowledge-acquisition\n</code></pre></p> </li> <li> <p>Set up environment variables: <pre><code>cp .env.example .env\n# Edit .env with your configuration\n</code></pre></p> </li> </ol>"},{"location":"guide/getting-started/#quick-start","title":"Quick Start","text":"<ol> <li> <p>Configure your OpenAI API key:    Edit <code>.env</code> and add your OpenAI API key:    <pre><code>OPENAI_API_KEY=your-api-key-here\n</code></pre></p> </li> <li> <p>Initialize the database:    <pre><code>python scripts/init_db.py\n</code></pre></p> </li> <li> <p>Run the application:    <pre><code>python app.py\n</code></pre></p> </li> <li> <p>Open your browser and navigate to <code>http://localhost:8501</code></p> </li> </ol>"},{"location":"guide/getting-started/#basic-usage","title":"Basic Usage","text":"<ol> <li>Add Knowledge Sources:</li> <li>Upload documents</li> <li>Add URLs for scraping</li> <li> <p>Connect to data sources</p> </li> <li> <p>Process Knowledge:</p> </li> <li>Trigger knowledge extraction</li> <li>Monitor processing status</li> <li> <p>View extracted knowledge</p> </li> <li> <p>Query Knowledge:</p> </li> <li>Use natural language queries</li> <li>Explore knowledge graph</li> <li>Export results</li> </ol>"},{"location":"guide/getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Read the Configuration Guide for detailed setup</li> <li>Check out the Examples for common use cases</li> <li>Review the API Documentation for integration</li> <li>Join our Community</li> </ul>"},{"location":"status/changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"status/changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"status/changelog/#added","title":"Added","text":"<ul> <li>Knowledge consolidation system (in progress)</li> <li>Advanced RAG system features</li> <li>Enhanced documentation structure</li> <li>Additional test coverage</li> </ul>"},{"location":"status/changelog/#changed","title":"Changed","text":"<ul> <li>Improved performance optimization</li> <li>Enhanced error handling</li> <li>Updated documentation</li> </ul>"},{"location":"status/changelog/#fixed","title":"Fixed","text":"<ul> <li>Various bug fixes</li> <li>Performance issues</li> <li>Documentation gaps</li> </ul>"},{"location":"status/changelog/#020-2025-02-11","title":"[0.2.0] - 2025-02-11","text":""},{"location":"status/changelog/#added_1","title":"Added","text":"<ul> <li>GitHub Actions for CI/CD</li> <li>MkDocs with Material theme</li> <li>Basic documentation structure</li> <li>PDF processing support</li> <li>New API endpoints</li> <li>Initial test suite</li> </ul>"},{"location":"status/changelog/#changed_1","title":"Changed","text":"<ul> <li>Improved RAG system accuracy</li> <li>Enhanced documentation</li> <li>Updated project structure</li> <li>Optimized performance</li> </ul>"},{"location":"status/changelog/#fixed_1","title":"Fixed","text":"<ul> <li>Various bug fixes</li> <li>Documentation issues</li> <li>Performance bottlenecks</li> </ul>"},{"location":"status/changelog/#010-2025-02-01","title":"[0.1.0] - 2025-02-01","text":""},{"location":"status/changelog/#added_2","title":"Added","text":"<ul> <li>Initial project setup</li> <li>Basic architecture</li> <li>Core components</li> <li>Basic scraping functionality</li> <li>Vector store integration</li> <li>RAG system prototype</li> <li>Basic documentation</li> </ul>"},{"location":"status/changelog/#changed_2","title":"Changed","text":"<ul> <li>Initial implementation</li> <li>Project structure</li> <li>Development workflow</li> </ul>"},{"location":"status/changelog/#fixed_2","title":"Fixed","text":"<ul> <li>Initial bug fixes</li> <li>Setup issues</li> <li>Configuration problems</li> </ul>"},{"location":"status/changelog/#types-of-changes","title":"Types of Changes","text":"<ul> <li><code>Added</code> for new features.</li> <li><code>Changed</code> for changes in existing functionality.</li> <li><code>Deprecated</code> for soon-to-be removed features.</li> <li><code>Removed</code> for now removed features.</li> <li><code>Fixed</code> for any bug fixes.</li> <li><code>Security</code> in case of vulnerabilities.</li> </ul>"},{"location":"status/changelog/#versioning","title":"Versioning","text":"<p>We use SemVer for versioning. For the versions available, see the tags on this repository.</p>"},{"location":"status/changelog/#release-process","title":"Release Process","text":"<ol> <li>Update the changelog</li> <li>Update version numbers</li> <li>Create release branch</li> <li>Run tests</li> <li>Create tag</li> <li>Deploy to production</li> <li>Merge to main</li> </ol>"},{"location":"status/changelog/#support","title":"Support","text":"<p>For support, please create an issue in the issue tracker.</p>"},{"location":"status/overview/","title":"Project Status Overview","text":""},{"location":"status/overview/#current-status","title":"Current Status","text":"<p>The Knowledge Acquisition project is currently in active development. Here's a high-level overview of the project status:</p>"},{"location":"status/overview/#completed-features","title":"Completed Features","text":"<ul> <li>Basic project structure and architecture</li> <li>Core components implementation</li> <li>Initial documentation setup</li> <li>GitHub repository and CI/CD pipeline</li> <li>Standardized development environment (conda)</li> <li>Basic scraping functionality</li> <li>Vector store integration</li> <li>RAG system prototype</li> </ul>"},{"location":"status/overview/#in-progress","title":"In Progress","text":"<ul> <li>Expanding test coverage</li> <li>Enhancing documentation</li> <li>Implementing knowledge consolidation</li> <li>Improving RAG system</li> <li>Adding more data sources</li> <li>Performance optimization</li> </ul>"},{"location":"status/overview/#planned-features","title":"Planned Features","text":"<ul> <li>Advanced UI/UX improvements</li> <li>Additional data source integrations</li> <li>Enhanced knowledge graph capabilities</li> <li>Automated knowledge validation</li> <li>Performance monitoring dashboard</li> <li>API rate limiting and security</li> </ul>"},{"location":"status/overview/#development-environment","title":"Development Environment","text":""},{"location":"status/overview/#python-environment","title":"Python Environment","text":"<ul> <li>Using conda environment: <code>knowledge-acquisition</code></li> <li>Python version: 3.11</li> <li>Key dependencies:</li> <li>PyTorch</li> <li>OpenAI</li> <li>FastAPI</li> <li>ChromaDB</li> <li>Langchain</li> </ul>"},{"location":"status/overview/#key-metrics","title":"Key Metrics","text":""},{"location":"status/overview/#code-quality","title":"Code Quality","text":"<ul> <li>Test Coverage: ~60%</li> <li>Code Documentation: ~80%</li> <li>Linting Score: 9.2/10</li> </ul>"},{"location":"status/overview/#performance","title":"Performance","text":"<ul> <li>Average Query Time: ~2s</li> <li>Knowledge Processing Rate: ~100 docs/hour</li> <li>System Uptime: 99.9%</li> </ul>"},{"location":"status/overview/#development-activity","title":"Development Activity","text":"<ul> <li>Active Contributors: 3</li> <li>Open Issues: 15</li> <li>Pull Requests: 5</li> <li>Last Release: v0.2.0</li> </ul>"},{"location":"status/overview/#recent-updates","title":"Recent Updates","text":""},{"location":"status/overview/#latest-release-v020","title":"Latest Release (v0.2.0)","text":"<ul> <li>Improved RAG system accuracy</li> <li>Added support for PDF processing</li> <li>Enhanced documentation</li> <li>Fixed various bugs</li> <li>Added new API endpoints</li> </ul>"},{"location":"status/overview/#current-sprint-focus","title":"Current Sprint Focus","text":"<ol> <li>Implementing knowledge consolidation</li> <li>Expanding test coverage</li> <li>Optimizing performance</li> <li>Enhancing documentation</li> <li>Adding new features</li> </ol>"},{"location":"status/overview/#known-issues","title":"Known Issues","text":""},{"location":"status/overview/#critical","title":"Critical","text":"<ul> <li>None currently</li> </ul>"},{"location":"status/overview/#high-priority","title":"High Priority","text":"<ul> <li>Rate limiting needs implementation</li> <li>Some edge cases in PDF processing</li> <li>Memory optimization needed for large documents</li> </ul>"},{"location":"status/overview/#medium-priority","title":"Medium Priority","text":"<ul> <li>UI improvements needed</li> <li>Better error handling in some components</li> <li>Documentation gaps in advanced features</li> </ul>"},{"location":"status/overview/#next-steps","title":"Next Steps","text":"<ol> <li>Complete knowledge consolidation system</li> <li>Implement remaining test cases</li> <li>Deploy monitoring system</li> <li>Add more data source integrations</li> <li>Enhance user interface</li> </ol>"},{"location":"status/overview/#resources","title":"Resources","text":"<ul> <li>Project Repository</li> <li>Documentation</li> <li>Issue Tracker</li> <li>Project Board</li> </ul>"},{"location":"status/roadmap/","title":"Project Roadmap","text":""},{"location":"status/roadmap/#q1-2025","title":"Q1 2025","text":""},{"location":"status/roadmap/#february","title":"February","text":""},{"location":"status/roadmap/#week-1-2","title":"Week 1-2","text":"<ul> <li>[x] Initial project setup</li> <li>[x] Basic architecture design</li> <li>[x] Core component implementation</li> <li>[x] GitHub repository setup</li> <li>[x] CI/CD pipeline configuration</li> <li>[x] Development environment standardization (conda)</li> </ul>"},{"location":"status/roadmap/#week-3-4","title":"Week 3-4","text":"<ul> <li>[ ] Complete documentation structure</li> <li>[ ] Implement basic test suite</li> <li>[ ] Knowledge consolidation system</li> <li>[ ] Performance optimization</li> <li>[ ] Security enhancements</li> </ul>"},{"location":"status/roadmap/#march","title":"March","text":""},{"location":"status/roadmap/#week-1-2_1","title":"Week 1-2","text":"<ul> <li>[ ] Advanced RAG system features</li> <li>[ ] Knowledge graph improvements</li> <li>[ ] Additional data source support</li> <li>[ ] Enhanced error handling</li> <li>[ ] Monitoring system implementation</li> </ul>"},{"location":"status/roadmap/#week-3-4_1","title":"Week 3-4","text":"<ul> <li>[ ] UI/UX improvements</li> <li>[ ] API rate limiting</li> <li>[ ] Performance dashboard</li> <li>[ ] Documentation expansion</li> <li>[ ] Bug fixes and optimizations</li> </ul>"},{"location":"status/roadmap/#q2-2025","title":"Q2 2025","text":""},{"location":"status/roadmap/#april","title":"April","text":""},{"location":"status/roadmap/#week-1-2_2","title":"Week 1-2","text":"<ul> <li>[ ] Advanced search capabilities</li> <li>[ ] Multi-language support</li> <li>[ ] Custom embedding models</li> <li>[ ] Enhanced PDF processing</li> <li>[ ] API documentation updates</li> </ul>"},{"location":"status/roadmap/#week-3-4_2","title":"Week 3-4","text":"<ul> <li>[ ] Knowledge validation system</li> <li>[ ] Automated testing expansion</li> <li>[ ] Performance benchmarking</li> <li>[ ] Security audit</li> <li>[ ] Documentation refinement</li> </ul>"},{"location":"status/roadmap/#may","title":"May","text":""},{"location":"status/roadmap/#week-1-2_3","title":"Week 1-2","text":"<ul> <li>[ ] Advanced analytics</li> <li>[ ] Custom visualization tools</li> <li>[ ] Enhanced monitoring</li> <li>[ ] API gateway implementation</li> <li>[ ] Cache optimization</li> </ul>"},{"location":"status/roadmap/#week-3-4_3","title":"Week 3-4","text":"<ul> <li>[ ] Machine learning enhancements</li> <li>[ ] Knowledge graph visualization</li> <li>[ ] Advanced search features</li> <li>[ ] Performance optimization</li> <li>[ ] Documentation updates</li> </ul>"},{"location":"status/roadmap/#june","title":"June","text":""},{"location":"status/roadmap/#week-1-2_4","title":"Week 1-2","text":"<ul> <li>[ ] Enterprise features</li> <li>[ ] Advanced security features</li> <li>[ ] Custom integrations</li> <li>[ ] Performance tuning</li> <li>[ ] Documentation completion</li> </ul>"},{"location":"status/roadmap/#week-3-4_4","title":"Week 3-4","text":"<ul> <li>[ ] Final testing</li> <li>[ ] Bug fixes</li> <li>[ ] Performance optimization</li> <li>[ ] Documentation review</li> <li>[ ] Release v1.0</li> </ul>"},{"location":"status/roadmap/#future-plans","title":"Future Plans","text":""},{"location":"status/roadmap/#q3-2025","title":"Q3 2025","text":"<ul> <li>Advanced machine learning features</li> <li>Custom model training support</li> <li>Enhanced visualization tools</li> <li>Additional language support</li> <li>Enterprise security features</li> </ul>"},{"location":"status/roadmap/#q4-2025","title":"Q4 2025","text":"<ul> <li>Cloud deployment options</li> <li>Advanced analytics dashboard</li> <li>Custom integration framework</li> <li>Enhanced performance tools</li> <li>Advanced security features</li> </ul>"},{"location":"status/roadmap/#2026","title":"2026","text":""},{"location":"status/roadmap/#q1","title":"Q1","text":"<ul> <li>Advanced AI capabilities</li> <li>Custom model marketplace</li> <li>Enhanced enterprise features</li> <li>Advanced analytics tools</li> <li>Performance optimization</li> </ul>"},{"location":"status/roadmap/#q2","title":"Q2","text":"<ul> <li>Global deployment support</li> <li>Advanced security features</li> <li>Custom integration tools</li> <li>Enhanced monitoring</li> <li>Documentation expansion</li> </ul>"},{"location":"status/roadmap/#success-metrics","title":"Success Metrics","text":""},{"location":"status/roadmap/#technical-metrics","title":"Technical Metrics","text":"<ul> <li>95% test coverage</li> <li>Sub-second query response</li> <li>99.99% uptime</li> <li>&lt;100ms average latency</li> </ul>"},{"location":"status/roadmap/#business-metrics","title":"Business Metrics","text":"<ul> <li>1000+ active users</li> <li>95% user satisfaction</li> <li>50+ enterprise clients</li> <li>24/7 support coverage</li> </ul>"},{"location":"status/roadmap/#development-metrics","title":"Development Metrics","text":"<ul> <li>Weekly releases</li> <li>&lt;24h bug resolution</li> <li>&lt;1% error rate</li> <li>100% documentation coverage</li> </ul>"}]}